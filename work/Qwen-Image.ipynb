{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc8541e5-4e43-4146-aeca-0d879f129989",
   "metadata": {},
   "source": [
    "https://huggingface.co/Qwen/Qwen-Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a15e221-0b87-4e80-a198-124346b751f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/diffusers\n",
      "  Cloning https://github.com/huggingface/diffusers to /tmp/pip-req-build-yflj8b9h\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers /tmp/pip-req-build-yflj8b9h\n",
      "  Resolved https://github.com/huggingface/diffusers to commit 7a2b78bf0f788d311cc96b61e660a8e13e3b1e63\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib_metadata in /opt/conda/lib/python3.12/site-packages (from diffusers==0.36.0.dev0) (8.6.1)\n",
      "Collecting filelock (from diffusers==0.36.0.dev0)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub>=0.34.0 (from diffusers==0.36.0.dev0)\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from diffusers==0.36.0.dev0) (2.1.3)\n",
      "Collecting regex!=2019.12.17 (from diffusers==0.36.0.dev0)\n",
      "  Using cached regex-2025.7.34-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from diffusers==0.36.0.dev0) (2.32.3)\n",
      "Collecting safetensors>=0.3.1 (from diffusers==0.36.0.dev0)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.12/site-packages (from diffusers==0.36.0.dev0) (11.1.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.34.0->diffusers==0.36.0.dev0) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.34.0->diffusers==0.36.0.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.34.0->diffusers==0.36.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.34.0->diffusers==0.36.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.34.0->diffusers==0.36.0.dev0) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.34.0->diffusers==0.36.0.dev0)\n",
      "  Using cached hf_xet-1.1.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.12/site-packages (from importlib_metadata->diffusers==0.36.0.dev0) (3.21.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->diffusers==0.36.0.dev0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->diffusers==0.36.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->diffusers==0.36.0.dev0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->diffusers==0.36.0.dev0) (2025.1.31)\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Using cached regex-2025.7.34-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (801 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached hf_xet-1.1.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Building wheels for collected packages: diffusers\n",
      "  Building wheel for diffusers (pyproject.toml) ... \u001b[done\n",
      "\u001b[?25h  Created wheel for diffusers: filename=diffusers-0.36.0.dev0-py3-none-any.whl size=4121536 sha256=0f84bd56cbf9b33118254912f2f0a1a0efd6d1db8593b5fd1cadaff6ce9a38f3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7yxh1i2l/wheels/90/d4/44/a58bc00fb405fefb633b0d9d2307f6e3aec6cc1775d82555d3\n",
      "Successfully built diffusers\n",
      "Installing collected packages: safetensors, regex, hf-xet, filelock, huggingface-hub, diffusers\n",
      "Successfully installed diffusers-0.36.0.dev0 filelock-3.19.1 hf-xet-1.1.8 huggingface-hub-0.34.4 regex-2025.7.34 safetensors-0.6.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95383a9-8d09-4e9e-b10a-6bfb4f324f73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (75.8.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch) (2025.3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.4.0 (from torch)\n",
      "  Using cached triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
      "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "Using cached torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.6 MB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "Successfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 torch-2.8.0 torchvision-0.23.0 triton-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5c26f1-c8eb-41a7-86cf-0639beb6235d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.8)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Using cached transformers-4.55.2-py3-none-any.whl (11.3 MB)\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "Successfully installed tokenizers-0.21.4 transformers-4.55.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc74f22f-e845-4014-9bcc-f5eb7ecabd5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.12/site-packages (from accelerate) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /opt/conda/lib/python3.12/site-packages (from accelerate) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.8)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (75.8.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.1.31)\n",
      "Downloading accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac5c516-21ce-45ab-b2ff-b195c86d9501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c9eed6e-7287-46be-a2dc-a4b49c20d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen-Image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a3c4707-d86e-4f95-98b7-2fca85e17a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch_dtype = torch.bfloat16\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    torch_dtype = torch.float32\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb2cbdca-a147-4da4-9014-8e19aece46f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64015beb-c30e-499f-bc81-d107b528dd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1922c4cea95488999d43d5fe4909653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 27 files:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ace3ea03e84c9c99410a11cb9e201e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00004-of-00004.safete(…):   0%|          | 0.00/1.69G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cda6453e5641d7bf522d1aa0f84ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00001-of-00004.safete(…):   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3f02a714084315be2769f1989f7d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(…):   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ae7e74c1d645fa9eb7a083ac61bcde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(…):   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c543466899e47508f85d877e278ff0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00003-of-00004.safete(…):   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7ead46dc14464590cf432efef36c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(…):   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58168befc744ab1b6d22fc4bcf826ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(…):   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d64277bd38446f8a01b3fc31f2c734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00002-of-00004.safete(…):   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33515128ab8c433d9edefe37bfe483e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(…):   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c11bafd83d4209801ae301f1d6e443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(…):   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb02d57b9be84461ad670b48bb9c2fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(…):   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b420713441874069b545186afb767213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(…):   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb7f1cef958480ea80fae30327c93a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(…):   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61cf4ea0e0d1422faad4db46f278fd6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'pooled_projection_dim': 768} were passed to QwenImageTransformer2DModel, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c756a5e4def48c79e9698122a4668ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c22ec4309aa424d9f476a3b7fabfb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = DiffusionPipeline.from_pretrained(model_name, torch_dtype=torch_dtype)\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26bfa1c5-368a-420f-aa74-26e91956b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_magic = {\n",
    "    \"en\": \", Ultra HD, 4K, cinematic composition.\", # for english prompt\n",
    "    \"zh\": \", 超清，4K，电影级构图.\" # for chinese prompt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a68020d-3c0f-4393-9875-d585b5480df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''At the entrance to the ski resort's coffee shop, there is a chalkboard sign that reads \"IMOKURING 😊 $2 per cup\" with a neon light beside it displaying \"Welcome\". Next to that is a poster of Snoopy skiing. Ultra HD, 4K, cinematic composition'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60b017e1-3f72-4b39-9d8b-18663e427255",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_prompt = \" \" # using an empty string if you do not have specific concept to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a873a2f3-8606-4c90-ac04-c7a8e272b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate with different aspect ratios\n",
    "aspect_ratios = {\n",
    "    \"1:1\": (1328, 1328),\n",
    "    \"16:9\": (1664, 928),\n",
    "    \"9:16\": (928, 1664),\n",
    "    \"4:3\": (1472, 1140),\n",
    "    \"3:4\": (1140, 1472),\n",
    "    \"3:2\": (1584, 1056),\n",
    "    \"2:3\": (1056, 1584),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0f7659a-f350-4efc-830e-e518ff32f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = aspect_ratios[\"16:9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e788be4d-15dd-4400-aeb6-c08551d4409c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc85ac0ad5494a38b43df50be44aa4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = pipe(\n",
    "    prompt=prompt + positive_magic[\"en\"],\n",
    "    negative_prompt=negative_prompt,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    num_inference_steps=50,\n",
    "    true_cfg_scale=4.0,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(42)\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33978f3e-6828-4149-9762-30829906caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.save(\"example3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ff873-dc25-484f-9dd3-d9c7a681f166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
