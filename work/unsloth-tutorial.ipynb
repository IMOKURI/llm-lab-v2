{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b58783c2-01a5-4b50-a446-30126e272aff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.8.9-py3-none-any.whl.metadata (52 kB)\n",
      "Collecting unsloth_zoo>=2025.8.8 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.8.8-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting torch>=2.4.0 (from unsloth)\n",
      "  Using cached torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Using cached xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting bitsandbytes (from unsloth)\n",
      "  Using cached bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
      "Collecting triton>=3.0.0 (from unsloth)\n",
      "  Using cached triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from unsloth) (24.2)\n",
      "Collecting tyro (from unsloth)\n",
      "  Using cached tyro-0.9.28-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3 (from unsloth)\n",
      "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting datasets<4.0.0,>=3.4.1 (from unsloth)\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentencepiece>=0.2.0 (from unsloth)\n",
      "  Using cached sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from unsloth) (7.0.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.12/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from unsloth) (2.1.3)\n",
      "Collecting accelerate>=0.34.1 (from unsloth)\n",
      "  Using cached accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n",
      "  Using cached trl-0.21.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting peft!=0.11.0,>=0.7.1 (from unsloth)\n",
      "  Downloading peft-0.17.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.12/site-packages (from unsloth) (5.29.3)\n",
      "Collecting huggingface_hub>=0.34.0 (from unsloth)\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting hf_transfer (from unsloth)\n",
      "  Using cached hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting diffusers (from unsloth)\n",
      "  Using cached diffusers-0.35.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting torchvision (from unsloth)\n",
      "  Using cached torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
      "Collecting safetensors>=0.4.3 (from accelerate>=0.34.1->unsloth)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting filelock (from datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets<4.0.0,>=3.4.1->unsloth) (19.0.1)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.12/site-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.32.3)\n",
      "Collecting xxhash (from datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets<4.0.0,>=3.4.1->unsloth)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub>=0.34.0->unsloth) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub>=0.34.0->unsloth)\n",
      "  Using cached hf_xet-1.1.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (75.8.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3->unsloth)\n",
      "  Using cached regex-2025.7.34-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3->unsloth)\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting torchao (from unsloth_zoo>=2025.8.8->unsloth)\n",
      "  Using cached torchao-0.12.0-cp39-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.8.8->unsloth)\n",
      "  Using cached cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.12/site-packages (from unsloth_zoo>=2025.8.8->unsloth) (11.1.0)\n",
      "Collecting msgspec (from unsloth_zoo>=2025.8.8->unsloth)\n",
      "  Using cached msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: importlib_metadata in /opt/conda/lib/python3.12/site-packages (from diffusers->unsloth) (8.6.1)\n",
      "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
      "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=11.1.0 (from tyro->unsloth)\n",
      "  Using cached rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
      "  Using cached shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
      "  Using cached typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub>=0.34.0->unsloth)\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (3.11.13)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2025.1.31)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro->unsloth)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich>=11.1.0->tyro->unsloth) (2.19.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.12/site-packages (from importlib_metadata->diffusers->unsloth) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.18.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth) (1.17.0)\n",
      "Downloading unsloth-2025.8.9-py3-none-any.whl (311 kB)\n",
      "Using cached accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
      "Using cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Downloading peft-0.17.1-py3-none-any.whl (504 kB)\n",
      "Using cached sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "Using cached torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
      "Using cached triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached trl-0.21.0-py3-none-any.whl (511 kB)\n",
      "Downloading unsloth_zoo-2025.8.8-py3-none-any.whl (184 kB)\n",
      "Using cached xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
      "Using cached bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
      "Using cached diffusers-0.35.1-py3-none-any.whl (4.1 MB)\n",
      "Using cached hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Using cached torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.6 MB)\n",
      "Using cached tyro-0.9.28-py3-none-any.whl (129 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Using cached hf_xet-1.1.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached regex-2025.7.34-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (801 kB)\n",
      "Using cached rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Using cached shtab-1.7.2-py3-none-any.whl (14 kB)\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Using cached cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Using cached torchao-0.12.0-cp39-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: torchao, nvidia-cusparselt-cu12, xxhash, typing-extensions, triton, shtab, sentencepiece, safetensors, regex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, mdurl, hf-xet, hf_transfer, filelock, docstring-parser, dill, typeguard, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, markdown-it-py, huggingface_hub, tokenizers, rich, nvidia-cusolver-cu12, diffusers, tyro, transformers, torch, datasets, xformers, torchvision, cut_cross_entropy, bitsandbytes, accelerate, trl, peft, unsloth_zoo, unsloth\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.9\n",
      "    Uninstalling dill-0.3.9:\n",
      "      Successfully uninstalled dill-0.3.9\n",
      "Successfully installed accelerate-1.10.0 bitsandbytes-0.47.0 cut_cross_entropy-25.1.1 datasets-3.6.0 diffusers-0.35.1 dill-0.3.8 docstring-parser-0.17.0 filelock-3.19.1 hf-xet-1.1.8 hf_transfer-0.1.9 huggingface_hub-0.34.4 markdown-it-py-4.0.0 mdurl-0.1.2 msgspec-0.19.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 peft-0.17.1 regex-2025.7.34 rich-14.1.0 safetensors-0.6.2 sentencepiece-0.2.1 shtab-1.7.2 tokenizers-0.21.4 torch-2.8.0 torchao-0.12.0 torchvision-0.23.0 transformers-4.55.4 triton-3.4.0 trl-0.21.0 typeguard-4.4.4 typing-extensions-4.14.1 tyro-0.9.28 unsloth-2025.8.9 unsloth_zoo-2025.8.8 xformers-0.0.32.post2 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04a0ee1f-6325-4728-9850-173f1e5b89ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "accelerate                1.10.0\n",
      "aiohappyeyeballs          2.6.1\n",
      "aiohttp                   3.11.13\n",
      "aiosignal                 1.3.2\n",
      "alembic                   1.15.1\n",
      "altair                    5.5.0\n",
      "annotated-types           0.7.0\n",
      "anyio                     4.8.0\n",
      "archspec                  0.2.5\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 3.0.0\n",
      "async_generator           1.10\n",
      "async-lru                 2.0.4\n",
      "attrs                     25.3.0\n",
      "babel                     2.17.0\n",
      "beautifulsoup4            4.13.3\n",
      "bitsandbytes              0.47.0\n",
      "bleach                    6.2.0\n",
      "blinker                   1.9.0\n",
      "bokeh                     3.7.0\n",
      "boltons                   24.0.0\n",
      "Bottleneck                1.4.2\n",
      "Brotli                    1.1.0\n",
      "cached-property           1.5.2\n",
      "certifi                   2025.1.31\n",
      "certipy                   0.2.1\n",
      "cffi                      1.17.1\n",
      "charset-normalizer        3.4.1\n",
      "click                     8.1.8\n",
      "cloudpickle               3.1.1\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.2\n",
      "conda                     25.1.1\n",
      "conda-libmamba-solver     25.1.1\n",
      "conda-package-handling    2.4.0\n",
      "conda_package_streaming   0.11.0\n",
      "contourpy                 1.3.1\n",
      "cryptography              44.0.2\n",
      "cut-cross-entropy         25.1.1\n",
      "cycler                    0.12.1\n",
      "Cython                    3.0.12\n",
      "cytoolz                   1.0.1\n",
      "dask                      2025.2.0\n",
      "datasets                  3.6.0\n",
      "debugpy                   1.8.13\n",
      "decorator                 5.2.1\n",
      "defusedxml                0.7.1\n",
      "diffusers                 0.35.1\n",
      "dill                      0.3.8\n",
      "distributed               2025.2.0\n",
      "distro                    1.9.0\n",
      "docstring_parser          0.17.0\n",
      "et_xmlfile                2.0.0\n",
      "exceptiongroup            1.2.2\n",
      "executing                 2.1.0\n",
      "fastjsonschema            2.21.1\n",
      "filelock                  3.19.1\n",
      "fonttools                 4.56.0\n",
      "fqdn                      1.5.1\n",
      "frozendict                2.4.6\n",
      "frozenlist                1.5.0\n",
      "fsspec                    2025.3.0\n",
      "gitdb                     4.0.12\n",
      "GitPython                 3.1.44\n",
      "gmpy2                     2.1.5\n",
      "greenlet                  3.1.1\n",
      "h11                       0.14.0\n",
      "h2                        4.2.0\n",
      "h5py                      3.13.0\n",
      "hf_transfer               0.1.9\n",
      "hf-xet                    1.1.8\n",
      "hpack                     4.1.0\n",
      "httpcore                  1.0.7\n",
      "httpx                     0.28.1\n",
      "huggingface-hub           0.34.4\n",
      "hyperframe                6.1.0\n",
      "idna                      3.10\n",
      "imagecodecs               2024.12.30\n",
      "imageio                   2.37.0\n",
      "importlib_metadata        8.6.1\n",
      "importlib_resources       6.5.2\n",
      "ipykernel                 6.29.5\n",
      "ipympl                    0.9.6\n",
      "ipython                   8.34.0\n",
      "ipython_genutils          0.2.0\n",
      "ipython_pygments_lexers   1.1.1\n",
      "ipywidgets                8.1.5\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.2\n",
      "Jinja2                    3.1.6\n",
      "joblib                    1.4.2\n",
      "json5                     0.10.0\n",
      "jsonpatch                 1.33\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2024.10.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.12.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter-pluto-proxy       0.1.2\n",
      "jupyter_server            2.15.0\n",
      "jupyter_server_mathjax    0.2.6\n",
      "jupyter_server_proxy      4.4.0\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterhub                5.2.1\n",
      "jupyterlab                4.3.5\n",
      "jupyterlab_git            0.51.0\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "jupyterlab_widgets        3.0.13\n",
      "kiwisolver                1.4.8\n",
      "lazy_loader               0.4\n",
      "libmambapy                2.0.7\n",
      "llvmlite                  0.44.0\n",
      "locket                    1.0.0\n",
      "lz4                       4.3.3\n",
      "Mako                      1.3.9\n",
      "markdown-it-py            4.0.0\n",
      "MarkupSafe                3.0.2\n",
      "matplotlib                3.10.1\n",
      "matplotlib-inline         0.1.7\n",
      "mdurl                     0.1.2\n",
      "menuinst                  2.2.0\n",
      "mistune                   3.1.2\n",
      "mpmath                    1.3.0\n",
      "msgpack                   1.1.0\n",
      "msgspec                   0.19.0\n",
      "multidict                 6.1.0\n",
      "multiprocess              0.70.16\n",
      "munkres                   1.1.4\n",
      "narwhals                  1.30.0\n",
      "nbclassic                 1.2.0\n",
      "nbclient                  0.10.2\n",
      "nbconvert                 7.16.6\n",
      "nbdime                    4.0.2\n",
      "nbformat                  5.10.4\n",
      "nest_asyncio              1.6.0\n",
      "networkx                  3.4.2\n",
      "notebook                  7.3.2\n",
      "notebook_shim             0.2.4\n",
      "numba                     0.61.0\n",
      "numexpr                   2.10.2\n",
      "numpy                     2.1.3\n",
      "nvidia-cublas-cu12        12.8.4.1\n",
      "nvidia-cuda-cupti-cu12    12.8.90\n",
      "nvidia-cuda-nvrtc-cu12    12.8.93\n",
      "nvidia-cuda-runtime-cu12  12.8.90\n",
      "nvidia-cudnn-cu12         9.10.2.21\n",
      "nvidia-cufft-cu12         11.3.3.83\n",
      "nvidia-cufile-cu12        1.13.1.3\n",
      "nvidia-curand-cu12        10.3.9.90\n",
      "nvidia-cusolver-cu12      11.7.3.90\n",
      "nvidia-cusparse-cu12      12.5.8.93\n",
      "nvidia-cusparselt-cu12    0.7.1\n",
      "nvidia-nccl-cu12          2.27.3\n",
      "nvidia-nvjitlink-cu12     12.8.93\n",
      "nvidia-nvtx-cu12          12.8.90\n",
      "oauthlib                  3.2.2\n",
      "openpyxl                  3.1.5\n",
      "overrides                 7.7.0\n",
      "packaging                 24.2\n",
      "pamela                    1.2.0\n",
      "pandas                    2.2.3\n",
      "pandocfilters             1.5.0\n",
      "parso                     0.8.4\n",
      "partd                     1.4.2\n",
      "patsy                     1.0.1\n",
      "peft                      0.17.1\n",
      "pexpect                   4.9.0\n",
      "pickleshare               0.7.5\n",
      "pillow                    11.1.0\n",
      "pip                       25.0.1\n",
      "pkgutil_resolve_name      1.3.10\n",
      "platformdirs              4.3.6\n",
      "pluggy                    1.5.0\n",
      "prometheus_client         0.21.1\n",
      "prompt_toolkit            3.0.50\n",
      "propcache                 0.2.1\n",
      "protobuf                  5.29.3\n",
      "psutil                    7.0.0\n",
      "ptyprocess                0.7.0\n",
      "pure_eval                 0.2.3\n",
      "py-cpuinfo                9.0.0\n",
      "pyarrow                   19.0.1\n",
      "pycosat                   0.6.6\n",
      "pycparser                 2.22\n",
      "pydantic                  2.10.6\n",
      "pydantic_core             2.27.2\n",
      "Pygments                  2.19.1\n",
      "PyJWT                     2.10.1\n",
      "pyparsing                 3.2.1\n",
      "PySocks                   1.7.1\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        2.0.7\n",
      "pytz                      2024.1\n",
      "PyWavelets                1.8.0\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.3.0\n",
      "referencing               0.36.2\n",
      "regex                     2025.7.34\n",
      "requests                  2.32.3\n",
      "rfc3339_validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rich                      14.1.0\n",
      "rpds-py                   0.23.1\n",
      "rpy2                      3.5.11\n",
      "ruamel.yaml               0.18.10\n",
      "ruamel.yaml.clib          0.2.8\n",
      "safetensors               0.6.2\n",
      "scikit-image              0.25.2\n",
      "scikit-learn              1.6.1\n",
      "scipy                     1.15.2\n",
      "seaborn                   0.13.2\n",
      "Send2Trash                1.8.3\n",
      "sentencepiece             0.2.1\n",
      "setuptools                75.8.2\n",
      "shtab                     1.7.2\n",
      "simpervisor               1.0.0\n",
      "simplegeneric             0.8.1\n",
      "six                       1.17.0\n",
      "smmap                     5.0.2\n",
      "sniffio                   1.3.1\n",
      "sortedcontainers          2.4.0\n",
      "soupsieve                 2.5\n",
      "SQLAlchemy                2.0.39\n",
      "stack_data                0.6.3\n",
      "statsmodels               0.14.4\n",
      "sympy                     1.13.3\n",
      "tables                    3.10.2\n",
      "tblib                     3.0.0\n",
      "terminado                 0.18.1\n",
      "threadpoolctl             3.6.0\n",
      "tifffile                  2025.3.13\n",
      "tinycss2                  1.4.0\n",
      "tokenizers                0.21.4\n",
      "tomli                     2.2.1\n",
      "toolz                     1.0.0\n",
      "torch                     2.8.0\n",
      "torchao                   0.12.0\n",
      "torchvision               0.23.0\n",
      "tornado                   6.4.2\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "transformers              4.55.4\n",
      "triton                    3.4.0\n",
      "trl                       0.21.0\n",
      "truststore                0.10.1\n",
      "typeguard                 4.4.4\n",
      "types-python-dateutil     2.9.0.20241206\n",
      "typing_extensions         4.14.1\n",
      "typing_utils              0.1.0\n",
      "tyro                      0.9.28\n",
      "tzdata                    2025.1\n",
      "tzlocal                   5.3\n",
      "unicodedata2              16.0.0\n",
      "unsloth                   2025.8.9\n",
      "unsloth_zoo               2025.8.8\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.3.0\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.11.1\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "wheel                     0.45.1\n",
      "widgetsnbextension        4.0.13\n",
      "xformers                  0.0.32.post2\n",
      "xlrd                      2.0.1\n",
      "xxhash                    3.5.0\n",
      "xyzservices               2025.1.0\n",
      "yarl                      1.18.3\n",
      "zict                      3.0.0\n",
      "zipp                      3.21.0\n",
      "zstandard                 0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0f7006f-e2fd-4e01-83fb-20a956c309a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 25 00:40:19 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 NVL                Off |   00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   28C    P0             60W /  400W |       1MiB /  95830MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57e7bdc-90d8-4138-9a1e-3baaccee1f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b45d417f-9174-4b9a-9105-03873f719bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "844d9d9a-7a1a-4bb4-9b6d-525936b10570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.8.9: Fast Gemma3 patching. Transformers: 4.55.4.\n",
      "   \\\\   /|    NVIDIA H100 NVL. Num GPUs = 1. Max memory: 93.096 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fbe2523ad4433b9e77c89d60965112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fe13a0cf384d99a3470fb80f84ac95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/233 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d5d28d89844a21a7044b4dc6437294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78cc3f29eda24754ac3f4b238c0be8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e002a79498da42388dcbcf26b2b1e557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8785ad4a621448f3a3f2dc06c4326457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d8d47db1de4998aa45c12f6aff2e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/670 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6e104fe0fe428eb15e469469f84ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-3-270m-it\",\n",
    "    max_seq_length = max_seq_length, # Choose any for long context!\n",
    "    load_in_4bit = False,  # 4 bit quantization to reduce memory\n",
    "    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
    "    # token = \"hf_...\", # use one if using gated models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb86cb42-0947-45cd-bf91-e87f944ec1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "model = FastModel.get_peft_model(\n",
    "    model,\n",
    "    r = 128, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 128,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d698af4e-2aa8-427b-8b59-09d406950b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d6329a2-95f4-437b-8a97-96a3e68acaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"gemma3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "332cff80-bc38-4a9a-901f-db74fdf73dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f6151b4-1ccc-41a4-ab17-014b911b2ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9eae2f2d9a4e6dbfb3fd96721ad06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec23841f73d4406bae5545de9eb46074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.csv:   0%|          | 0.00/161M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b233a8e864e94fbe9f2390a8ba25df44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.csv:   0%|          | 0.00/1.63M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b23a030ad94cea83fe42b267a058b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/99000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c13538ad903459a8a5676c66da79679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Thytu/ChessInstruct\", split = \"train[:10000]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f644a16-e319-4a62-b5e4-59cb68efb73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_chatml(example):\n",
    "    return {\n",
    "        \"conversations\": [\n",
    "            {\"role\": \"system\", \"content\": example[\"task\"]},\n",
    "            {\"role\": \"user\", \"content\": example[\"input\"]},\n",
    "            {\"role\": \"assistant\", \"content\": example[\"expected_output\"]}\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5c67817-4c40-4512-896c-0c17e8c8f0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f864c9e6fe42bb96506974164b3980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    convert_to_chatml\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8522c5c5-6662-4c91-838f-9344228b14c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': \"Given an incomplit set of chess moves and the game's final score, write the last missing chess move.\\n\\nInput Format: A comma-separated list of chess moves followed by the game score.\\nOutput Format: The missing chess move\",\n",
       " 'input': '{\"moves\": [\"c2c4\", \"g8f6\", \"b1c3\", \"c7c5\", \"g1f3\", \"e7e6\", \"e2e3\", \"d7d5\", \"d2d4\", \"b8c6\", \"c4d5\", \"e6d5\", \"f1e2\", \"c5c4\", \"c1d2\", \"f8b4\", \"a1c1\", \"e8g8\", \"b2b3\", \"b4a3\", \"c1b1\", \"c8f5\", \"b3c4\", \"f5b1\", \"d1b1\", \"d5c4\", \"e2c4\", \"a3b4\", \"e1g1\", \"a8c8\", \"f1d1\", \"d8a5\", \"c3e4\", \"f6e4\", \"b1e4\", \"b4d2\", \"f3d2\", \"c8c7\", \"d2f3\", \"c6b8\", \"c4b3\", \"b8d7\", \"e4f4\", \"c7c3\", \"e3e4\", \"a5b5\", \"e4e5\", \"a7a5\", \"f4e4\", \"a5a4\", \"b3d5\", \"h7h6\", \"d1b1\", \"b5d3\", \"e4d3\", \"c3d3\", \"e5e6\", \"d7f6\", \"e6f7\", \"g8h7\", \"d5e6\", \"g7g6\", \"h2h4\", \"f6e4\", \"b1b7\", \"h7g7\", \"b7a7\", \"d3d1\", \"g1h2\", \"e4f2\", \"a7a4\", \"d1h1\", \"h2g3\", \"f2e4\", \"g3f4\", \"e4d6\", \"f3e5\", \"h1h4\", \"f4e3\", \"d6f5\", \"e3d3\", \"f8d8\", \"e5d7\", \"h4g4\", \"f7f8b\", \"d8f8\", \"d7f8\", \"g7f8\", \"e6d5\", \"g4g3\", \"d3e4\", \"g3g2\", \"e4e5\", \"g2d2\", \"a4a8\", \"f8e7\", \"a8a7\", \"e7d8\", \"d5e6\", \"d2e2\", \"e5f6\", \"e2f2\", \"a7d7\", \"d8e8\", \"f6g6\", \"f5h4\", \"g6g7\", \"f2g2\", \"g7h7\", \"h4f3\", \"h7h6\", \"g2a2\", \"d4d5\", \"a2h2\", \"h6g7\", \"f3g5\", \"g7f6\", \"g5e4\", \"f6e5\", \"e4c3\", \"d7b7\", \"h2e2\", \"e5d4\", \"c3d5\", \"d4d5\", \"e2d2\", \"d5e5\", \"d2f2\", \"e6d5\", \"e8f8\", \"d5e6\", \"f2h2\", \"b7c7\", \"h2h5\", \"e6f5\", \"f8e8\", \"e5d6\", \"h5h6\", \"f5e6\", \"e8f8\", \"c7f7\", \"f8g8\", \"d6e5\", \"h6g6\", \"e5d5\", \"g8h8\", \"d5d6\", \"g6g5\", \"d6e7\", \"g5g7\", \"e7f6\", \"g7f7\", \"?\"], \"result\": \"1/2-1/2\"}',\n",
       " 'expected_output': '{\"missing move\": \"e6f7\"}',\n",
       " 'KIND': 'FIND_LAST_MOVE',\n",
       " 'conversations': [{'content': \"Given an incomplit set of chess moves and the game's final score, write the last missing chess move.\\n\\nInput Format: A comma-separated list of chess moves followed by the game score.\\nOutput Format: The missing chess move\",\n",
       "   'role': 'system'},\n",
       "  {'content': '{\"moves\": [\"c2c4\", \"g8f6\", \"b1c3\", \"c7c5\", \"g1f3\", \"e7e6\", \"e2e3\", \"d7d5\", \"d2d4\", \"b8c6\", \"c4d5\", \"e6d5\", \"f1e2\", \"c5c4\", \"c1d2\", \"f8b4\", \"a1c1\", \"e8g8\", \"b2b3\", \"b4a3\", \"c1b1\", \"c8f5\", \"b3c4\", \"f5b1\", \"d1b1\", \"d5c4\", \"e2c4\", \"a3b4\", \"e1g1\", \"a8c8\", \"f1d1\", \"d8a5\", \"c3e4\", \"f6e4\", \"b1e4\", \"b4d2\", \"f3d2\", \"c8c7\", \"d2f3\", \"c6b8\", \"c4b3\", \"b8d7\", \"e4f4\", \"c7c3\", \"e3e4\", \"a5b5\", \"e4e5\", \"a7a5\", \"f4e4\", \"a5a4\", \"b3d5\", \"h7h6\", \"d1b1\", \"b5d3\", \"e4d3\", \"c3d3\", \"e5e6\", \"d7f6\", \"e6f7\", \"g8h7\", \"d5e6\", \"g7g6\", \"h2h4\", \"f6e4\", \"b1b7\", \"h7g7\", \"b7a7\", \"d3d1\", \"g1h2\", \"e4f2\", \"a7a4\", \"d1h1\", \"h2g3\", \"f2e4\", \"g3f4\", \"e4d6\", \"f3e5\", \"h1h4\", \"f4e3\", \"d6f5\", \"e3d3\", \"f8d8\", \"e5d7\", \"h4g4\", \"f7f8b\", \"d8f8\", \"d7f8\", \"g7f8\", \"e6d5\", \"g4g3\", \"d3e4\", \"g3g2\", \"e4e5\", \"g2d2\", \"a4a8\", \"f8e7\", \"a8a7\", \"e7d8\", \"d5e6\", \"d2e2\", \"e5f6\", \"e2f2\", \"a7d7\", \"d8e8\", \"f6g6\", \"f5h4\", \"g6g7\", \"f2g2\", \"g7h7\", \"h4f3\", \"h7h6\", \"g2a2\", \"d4d5\", \"a2h2\", \"h6g7\", \"f3g5\", \"g7f6\", \"g5e4\", \"f6e5\", \"e4c3\", \"d7b7\", \"h2e2\", \"e5d4\", \"c3d5\", \"d4d5\", \"e2d2\", \"d5e5\", \"d2f2\", \"e6d5\", \"e8f8\", \"d5e6\", \"f2h2\", \"b7c7\", \"h2h5\", \"e6f5\", \"f8e8\", \"e5d6\", \"h5h6\", \"f5e6\", \"e8f8\", \"c7f7\", \"f8g8\", \"d6e5\", \"h6g6\", \"e5d5\", \"g8h8\", \"d5d6\", \"g6g5\", \"d6e7\", \"g5g7\", \"e7f6\", \"g7f7\", \"?\"], \"result\": \"1/2-1/2\"}',\n",
       "   'role': 'user'},\n",
       "  {'content': '{\"missing move\": \"e6f7\"}', 'role': 'assistant'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10f43dfc-a49a-4a3f-a26e-421fefc47e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(examples):\n",
    "   convos = examples[\"conversations\"]\n",
    "   texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False).removeprefix('<bos>') for convo in convos]\n",
    "   return { \"text\" : texts, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e071c97-cb54-4fea-b818-bae27f2f3ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53ebc8c78fe43988f99cbadca0cd0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(formatting_prompts_func, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed063e7d-7647-4ae5-9076-3e9f9dd03696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start_of_turn>user\\nGiven an incomplit set of chess moves and the game\\'s final score, write the last missing chess move.\\n\\nInput Format: A comma-separated list of chess moves followed by the game score.\\nOutput Format: The missing chess move\\n\\n{\"moves\": [\"c2c4\", \"g8f6\", \"b1c3\", \"c7c5\", \"g1f3\", \"e7e6\", \"e2e3\", \"d7d5\", \"d2d4\", \"b8c6\", \"c4d5\", \"e6d5\", \"f1e2\", \"c5c4\", \"c1d2\", \"f8b4\", \"a1c1\", \"e8g8\", \"b2b3\", \"b4a3\", \"c1b1\", \"c8f5\", \"b3c4\", \"f5b1\", \"d1b1\", \"d5c4\", \"e2c4\", \"a3b4\", \"e1g1\", \"a8c8\", \"f1d1\", \"d8a5\", \"c3e4\", \"f6e4\", \"b1e4\", \"b4d2\", \"f3d2\", \"c8c7\", \"d2f3\", \"c6b8\", \"c4b3\", \"b8d7\", \"e4f4\", \"c7c3\", \"e3e4\", \"a5b5\", \"e4e5\", \"a7a5\", \"f4e4\", \"a5a4\", \"b3d5\", \"h7h6\", \"d1b1\", \"b5d3\", \"e4d3\", \"c3d3\", \"e5e6\", \"d7f6\", \"e6f7\", \"g8h7\", \"d5e6\", \"g7g6\", \"h2h4\", \"f6e4\", \"b1b7\", \"h7g7\", \"b7a7\", \"d3d1\", \"g1h2\", \"e4f2\", \"a7a4\", \"d1h1\", \"h2g3\", \"f2e4\", \"g3f4\", \"e4d6\", \"f3e5\", \"h1h4\", \"f4e3\", \"d6f5\", \"e3d3\", \"f8d8\", \"e5d7\", \"h4g4\", \"f7f8b\", \"d8f8\", \"d7f8\", \"g7f8\", \"e6d5\", \"g4g3\", \"d3e4\", \"g3g2\", \"e4e5\", \"g2d2\", \"a4a8\", \"f8e7\", \"a8a7\", \"e7d8\", \"d5e6\", \"d2e2\", \"e5f6\", \"e2f2\", \"a7d7\", \"d8e8\", \"f6g6\", \"f5h4\", \"g6g7\", \"f2g2\", \"g7h7\", \"h4f3\", \"h7h6\", \"g2a2\", \"d4d5\", \"a2h2\", \"h6g7\", \"f3g5\", \"g7f6\", \"g5e4\", \"f6e5\", \"e4c3\", \"d7b7\", \"h2e2\", \"e5d4\", \"c3d5\", \"d4d5\", \"e2d2\", \"d5e5\", \"d2f2\", \"e6d5\", \"e8f8\", \"d5e6\", \"f2h2\", \"b7c7\", \"h2h5\", \"e6f5\", \"f8e8\", \"e5d6\", \"h5h6\", \"f5e6\", \"e8f8\", \"c7f7\", \"f8g8\", \"d6e5\", \"h6g6\", \"e5d5\", \"g8h8\", \"d5d6\", \"g6g5\", \"d6e7\", \"g5g7\", \"e7f6\", \"g7f7\", \"?\"], \"result\": \"1/2-1/2\"}<end_of_turn>\\n<start_of_turn>model\\n{\"missing move\": \"e6f7\"}<end_of_turn>\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5258fd1-6cbe-4993-9041-764b70012a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90ba8559-45fa-4185-859c-1744cf89e839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2516a80f3f234a89b3c1345f6158bc56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    eval_dataset = None, # Can set up evaluation!\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 8,\n",
    "        gradient_accumulation_steps = 1, # Use GA to mimic batch size!\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 100,\n",
    "        learning_rate = 5e-5, # Reduce to 2e-5 for long training runs\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir=\"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81f726bf-217b-49d7-b2b5-60a50d81f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import train_on_responses_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2da05d57-3045-4071-b747-fdb58a6f291f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182067c6f8ec47859a643d790e460aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<start_of_turn>user\\n\",\n",
    "    response_part = \"<start_of_turn>model\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2b0e63f-76ce-4dbc-bc8c-1503a5428334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos><start_of_turn>user\\nGiven an incomplit set of chess moves and the game\\'s final score, write the last missing chess move.\\n\\nInput Format: A comma-separated list of chess moves followed by the game score.\\nOutput Format: The missing chess move\\n\\n{\"moves\": [\"c2c4\", \"g8f6\", \"b1c3\", \"c7c5\", \"g1f3\", \"e7e6\", \"e2e3\", \"d7d5\", \"d2d4\", \"b8c6\", \"c4d5\", \"e6d5\", \"f1e2\", \"c5c4\", \"c1d2\", \"f8b4\", \"a1c1\", \"e8g8\", \"b2b3\", \"b4a3\", \"c1b1\", \"c8f5\", \"b3c4\", \"f5b1\", \"d1b1\", \"d5c4\", \"e2c4\", \"a3b4\", \"e1g1\", \"a8c8\", \"f1d1\", \"d8a5\", \"c3e4\", \"f6e4\", \"b1e4\", \"b4d2\", \"f3d2\", \"c8c7\", \"d2f3\", \"c6b8\", \"c4b3\", \"b8d7\", \"e4f4\", \"c7c3\", \"e3e4\", \"a5b5\", \"e4e5\", \"a7a5\", \"f4e4\", \"a5a4\", \"b3d5\", \"h7h6\", \"d1b1\", \"b5d3\", \"e4d3\", \"c3d3\", \"e5e6\", \"d7f6\", \"e6f7\", \"g8h7\", \"d5e6\", \"g7g6\", \"h2h4\", \"f6e4\", \"b1b7\", \"h7g7\", \"b7a7\", \"d3d1\", \"g1h2\", \"e4f2\", \"a7a4\", \"d1h1\", \"h2g3\", \"f2e4\", \"g3f4\", \"e4d6\", \"f3e5\", \"h1h4\", \"f4e3\", \"d6f5\", \"e3d3\", \"f8d8\", \"e5d7\", \"h4g4\", \"f7f8b\", \"d8f8\", \"d7f8\", \"g7f8\", \"e6d5\", \"g4g3\", \"d3e4\", \"g3g2\", \"e4e5\", \"g2d2\", \"a4a8\", \"f8e7\", \"a8a7\", \"e7d8\", \"d5e6\", \"d2e2\", \"e5f6\", \"e2f2\", \"a7d7\", \"d8e8\", \"f6g6\", \"f5h4\", \"g6g7\", \"f2g2\", \"g7h7\", \"h4f3\", \"h7h6\", \"g2a2\", \"d4d5\", \"a2h2\", \"h6g7\", \"f3g5\", \"g7f6\", \"g5e4\", \"f6e5\", \"e4c3\", \"d7b7\", \"h2e2\", \"e5d4\", \"c3d5\", \"d4d5\", \"e2d2\", \"d5e5\", \"d2f2\", \"e6d5\", \"e8f8\", \"d5e6\", \"f2h2\", \"b7c7\", \"h2h5\", \"e6f5\", \"f8e8\", \"e5d6\", \"h5h6\", \"f5e6\", \"e8f8\", \"c7f7\", \"f8g8\", \"d6e5\", \"h6g6\", \"e5d5\", \"g8h8\", \"d5d6\", \"g6g5\", \"d6e7\", \"g5g7\", \"e7f6\", \"g7f7\", \"?\"], \"result\": \"1/2-1/2\"}<end_of_turn>\\n<start_of_turn>model\\n{\"missing move\": \"e6f7\"}<end_of_turn>\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(trainer.train_dataset[100][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82e89fbe-a83e-49e2-b8ff-4dd07f486907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             {\"missing move\": \"e6f7\"}<end_of_turn>\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([tokenizer.pad_token_id if x == -100 else x for x in trainer.train_dataset[100][\"labels\"]]).replace(tokenizer.pad_token, \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0eec6cbb-0a25-4425-abaf-373ca68dc93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA H100 NVL. Max memory = 93.096 GB.\n",
      "0.635 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# @title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b11af132-bb77-49ab-a0ee-b6df5669baf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 10,000 | Num Epochs = 1 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 1 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 30,375,936 of 298,474,112 (10.18% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:43, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.858500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.930100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.577600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.688200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.688100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.703100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.555500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.539500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.798100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.634700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.403400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.674500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.687700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.571200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.664600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.534600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.593300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.691100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.484400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.469700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.368200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.528900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.463300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.394500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.426100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.531100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.318300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.663800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.233100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.458800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.401700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.525700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.280100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.352900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.368400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.317200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.389200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.420500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.493900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.531600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.535800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.275200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.458700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.451100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.393200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.335400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.294200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.473200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.391800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.362400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.408300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.362800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.391100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.269200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.286000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.457700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.318500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.380700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.350200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.355500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.264500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.511700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.334800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.234100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.434200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.442200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.294600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.302300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.282200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.306100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.328000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.245400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.281100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.435300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.337900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.311000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.231100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.242600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.413800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.290500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.327900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.334100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.399600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.326000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.328500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.265500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.356800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.320500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.366900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.269400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef11da64-04c7-4a75-ace3-e80cab97ae18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.1693 seconds used for training.\n",
      "1.02 minutes used for training.\n",
      "Peak reserved memory = 4.096 GB.\n",
      "Peak reserved memory for training = 3.461 GB.\n",
      "Peak reserved memory % of max memory = 4.4 %.\n",
      "Peak reserved memory for training % of max memory = 3.718 %.\n"
     ]
    }
   ],
   "source": [
    "# @title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b3645ac-0cf7-46bb-8092-93ebc1859369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 25 01:36:06 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 NVL                Off |   00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   40C    P0             93W /  400W |    5020MiB /  95830MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36c64637-3344-4fbb-b339-fe3006735e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {'role': 'system','content':dataset['conversations'][10][0]['content']},\n",
    "    {\"role\" : 'user', 'content' : dataset['conversations'][10][1]['content']}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    ").removeprefix('<bos>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c048674-66f6-4070-9518-7e478dd690a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c672478-b779-4b54-90d3-6c0dd3d62860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "Given an incomplit set of chess moves and the game's final score, write the last missing chess move.\n",
      "\n",
      "Input Format: A comma-separated list of chess moves followed by the game score.\n",
      "Output Format: The missing chess move\n",
      "\n",
      "{\"moves\": [\"e2e4\", \"c7c5\", \"g1f3\", \"e7e6\", \"d2d4\", \"c5d4\", \"f3d4\", \"g8f6\", \"b1c3\", \"f8b4\", \"e4e5\", \"f6e4\", \"d1g4\", \"e4c3\", \"g4g7\", \"h8f8\", \"a2a3\", \"c3b5\", \"a3b4\", \"b5d4\", \"c1g5\", \"d8b6\", \"g5h6\", \"d4c2\", \"e1d1\", \"b6b4\", \"d1c2\", \"b8c6\", \"f1e2\", \"d7d5\", \"g7f8\", \"b4f8\", \"h6f8\", \"e8f8\", \"f2f4\", \"a7a5\", \"a1a3\", \"c8d7\", \"h1d1\", \"c6e7\", \"c2d2\", \"a5a4\", \"d1c1\", \"d7c6\", \"g2g3\", \"a8b8\", \"c1c5\", \"b7b5\", \"b2b4\", \"a4b3\", \"a3b3\", \"b8a8\", \"b3b2\", \"a8a3\", \"b2c2\", \"c6e8\", \"c5c3\", \"a3a4\", \"c3c7\", \"a4a1\", \"c7b7\", \"a1h1\", \"b7b8\", \"b5b4\", \"e2b5\", \"b4b3\", \"c2c1\", \"h1h2\", \"d2c3\", \"e7f5\", \"b5e8\", \"b3b2\", \"e8a4\", \"f8g7\", \"b8b2\", \"h2h3\", \"b2b7\", \"h3g3\", \"c3b2\", \"g3g2\", \"b2b1\", \"f5d4\", \"a4e8\", \"d4e2\", \"e8f7\", \"e2c1\", \"f7e6\", \"g7f8\", \"b1c1\", \"g2e2\", \"b7f7\", \"f8e8\", \"e6d5\", \"h7h6\", \"e5e6\", \"e8d8\", \"c1d1\", \"e2b2\", \"d5c6\", \"b2b1\", \"d1d2\", \"b1b2\", \"d2e3\", \"b2b3\", \"e3e4\", \"b3b4\", \"e4e5\", \"b4b1\", \"e6e7\", \"d8c7\", \"e7e8q\", \"c7b6\", \"e8b8\", \"b6c5\", \"b8b1\", \"c5c4\", \"b1c2\", \"c4b4\", \"f7b7\", \"b4a3\", \"?\"], \"result\": \"1-0\"}<end_of_turn>\n",
      "<start_of_turn>model\n",
      "{\"missing move\": \"c2c1\"}<end_of_turn>\n"
     ]
    }
   ],
   "source": [
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 125,\n",
    "    temperature = 1, top_p = 0.95, top_k = 64,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e992c068-c095-49e1-97ff-42e0b2a47b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gemma-3/tokenizer_config.json',\n",
       " 'gemma-3/special_tokens_map.json',\n",
       " 'gemma-3/chat_template.jinja',\n",
       " 'gemma-3/tokenizer.model',\n",
       " 'gemma-3/added_tokens.json',\n",
       " 'gemma-3/tokenizer.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"gemma-3\")  # Local saving\n",
    "tokenizer.save_pretrained(\"gemma-3\")\n",
    "# model.push_to_hub(\"your_name/gemma-3\", token = \"...\") # Online saving\n",
    "# tokenizer.push_to_hub(\"your_name/gemma-3\", token = \"...\") # Online saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea410a6-0966-43d6-aa6f-84b240ac4b24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
